{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important, \n",
    "\n",
    "# The aim of this code is to convert the CSV file of\n",
    "# labels = missing words, and sentences with missing words\n",
    "# into a tensor of numbersthat can be passed through\n",
    "# the matching networks code just like the numpy array\n",
    "# used for the images in the original code based on the\n",
    "# Onmiglot dataset\n",
    "\n",
    "# The numbers in the tensor will be the numbers each word\n",
    "# refers to in the vocabulary we are building\n",
    "# We will not embed at this stage because this is\n",
    "# is done inside the matching network. We are, in effect,\n",
    "# not completing the TorchText proprocessing\n",
    "\n",
    "# This code is a mainly a mixture of two tutorials:\n",
    "# http://anie.me/On-Torchtext/\n",
    "# https://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "\n",
    "# Comments are a mixture of those from the tutorials (most of them)\n",
    "# and my own\n",
    "\n",
    "# Note to self, use Conda environment PyTorch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext.data import Iterator\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tackles</th>\n",
       "      <th>tadman had seven solo &lt;blank_token&gt; three assisted tackles and recorded a defensive touchdown after recovering chris johnson 's fumble late in the fourth quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tackles</td>\n",
       "      <td>defensive line coach bo davis resigned his pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tackles</td>\n",
       "      <td>N and N &lt; unk &gt; were linebackers paul nelson a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tackles</td>\n",
       "      <td>courtney &lt; unk &gt; was named the sec defensive p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tackles</td>\n",
       "      <td>williams also recorded eight solo &lt;blank_token...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tackles</td>\n",
       "      <td>behind defensive mvp burt miami had one player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tackles</td>\n",
       "      <td>in addition the ecu defense ranked eleventh na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tackles</td>\n",
       "      <td>burt the other mvp accumulated nine &lt;blank_tok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tackles</td>\n",
       "      <td>the other interception came from defensive bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tackles</td>\n",
       "      <td>brown finished the regular season with N &lt;blan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>amended</td>\n",
       "      <td>the constitution has since been &lt;blank_token&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>amended</td>\n",
       "      <td>the newly &lt;blank_token&gt; act did however rescin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>amended</td>\n",
       "      <td>while the N constitution remains in force it h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>amended</td>\n",
       "      <td>according to the ioc the existing legislation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>amended</td>\n",
       "      <td>both treaties however were &lt;blank_token&gt; to du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>amended</td>\n",
       "      <td>this was &lt;blank_token&gt; to a circle area with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>amended</td>\n",
       "      <td>he neglected to add a specific name to form a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>amended</td>\n",
       "      <td>mckay &lt;blank_token&gt; his legislation to provide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>amended</td>\n",
       "      <td>when the sport resumed in N batsmen were out o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>amended</td>\n",
       "      <td>after tudman 's death in N the constitution wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tackles  \\\n",
       "0   tackles   \n",
       "1   tackles   \n",
       "2   tackles   \n",
       "3   tackles   \n",
       "4   tackles   \n",
       "5   tackles   \n",
       "6   tackles   \n",
       "7   tackles   \n",
       "8   tackles   \n",
       "9   amended   \n",
       "10  amended   \n",
       "11  amended   \n",
       "12  amended   \n",
       "13  amended   \n",
       "14  amended   \n",
       "15  amended   \n",
       "16  amended   \n",
       "17  amended   \n",
       "18  amended   \n",
       "\n",
       "   tadman had seven solo <blank_token> three assisted tackles and recorded a defensive touchdown after recovering chris johnson 's fumble late in the fourth quarter  \n",
       "0   defensive line coach bo davis resigned his pos...                                                                                                                 \n",
       "1   N and N < unk > were linebackers paul nelson a...                                                                                                                 \n",
       "2   courtney < unk > was named the sec defensive p...                                                                                                                 \n",
       "3   williams also recorded eight solo <blank_token...                                                                                                                 \n",
       "4   behind defensive mvp burt miami had one player...                                                                                                                 \n",
       "5   in addition the ecu defense ranked eleventh na...                                                                                                                 \n",
       "6   burt the other mvp accumulated nine <blank_tok...                                                                                                                 \n",
       "7   the other interception came from defensive bac...                                                                                                                 \n",
       "8   brown finished the regular season with N <blan...                                                                                                                 \n",
       "9   the constitution has since been <blank_token> ...                                                                                                                 \n",
       "10  the newly <blank_token> act did however rescin...                                                                                                                 \n",
       "11  while the N constitution remains in force it h...                                                                                                                 \n",
       "12  according to the ioc the existing legislation ...                                                                                                                 \n",
       "13  both treaties however were <blank_token> to du...                                                                                                                 \n",
       "14  this was <blank_token> to a circle area with a...                                                                                                                 \n",
       "15  he neglected to add a specific name to form a ...                                                                                                                 \n",
       "16  mckay <blank_token> his legislation to provide...                                                                                                                 \n",
       "17  when the sport resumed in N batsmen were out o...                                                                                                                 \n",
       "18  after tudman 's death in N the constitution wa...                                                                                                                 "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what the data looks like\n",
    "\n",
    "pd.read_csv(\"data/train_experiments2.csv\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spacy to define a function to \n",
    "# tokenize, or split up, into individual words\n",
    "# the labels and sentences Note the labels are already\n",
    "# individual words\n",
    "\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "# We first define a Field, this is a class that contains\n",
    "# information on how you want the data preprocessed. It acts\n",
    "# like an instruction manual that data.TabularDataset will use.\n",
    "# We define two fields, one for the sentencesm and one for the\n",
    "# labels\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenizer)\n",
    "LABEL = data.Field(sequential=False, is_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fields know what to do when given raw data.\n",
    "# Now, we need to tell the fields what data it\n",
    "# should work on. This is where we use Datasets.\n",
    "\n",
    "# The splits method creates a dataset for the train\n",
    "# and test data by applying the same processing.\n",
    "\n",
    "train, test = data.TabularDataset.splits(\n",
    "        path='data/', train='train_experiments2.csv', test='test_experiments2.csv', format='csv',\n",
    "        fields=[('label', LABEL), ('sentence', TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.data.dataset.TabularDataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torchtext handles mapping words to integers, but\n",
    "# it has to be told the full range of words it should\n",
    "# handle.\n",
    "\n",
    "# We are currently building the vocab from the train\n",
    "# and test data\n",
    "\n",
    "TEXT.build_vocab(train, test)\n",
    "LABEL.build_vocab(train, test)\n",
    "\n",
    "# This makes torchtext go through all the elements in the\n",
    "# training set, check the contents corresponding to the TEXT\n",
    "# field, and register the words in its vocabulary. Torchtext\n",
    "# has its own class called Vocab for handling the vocabulary.\n",
    "# The Vocab class holds a mapping from word to id in its stoi\n",
    "# attribute and a reverse mapping in its itos attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x000001F497E5BEA0>, {'<unk>': 0, 'amended': 1, 'tackles': 2, 'borgnine': 3, 'sir': 4})\n"
     ]
    }
   ],
   "source": [
    "vocab = LABEL.vocab\n",
    "print(vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 0, 'amended': 1, 'tackles': 2, 'borgnine': 3, 'sir': 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary\n",
    "\n",
    "{i:vocab.stoi[i] for i in vocab.stoi if i!='label'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x00000288FCB2CEA0>, {'<unk>': 0, '<pad>': 1, '<': 2, '>': 3, 'the': 4, 'unk': 5, 'and': 6, 'blank_token': 7, 'to': 8, 'a': 9, 'N': 10, 'was': 11, 'in': 12, 'of': 13, 'for': 14, 'by': 15, 'after': 16, 'his': 17, 'defensive': 18, 'is': 19, 'principal': 20, 'that': 21, 'who': 22, 'with': 23, \"'s\": 24, 'assisted': 25, 'but': 26, 'fumble': 27, 'gold': 28, 'had': 29, 'he': 30, 'james': 31, 'seven': 32, 'they': 33, 'were': 34, 'while': 35, 'an': 36, 'between': 37, 'coach': 38, 'coin': 39, 'dollar': 40, 'egypt': 41, 'end': 42, 'gallipoli': 43, 'great': 44, 'guitar': 45, 'henry': 46, 'i.': 47, 'italy': 48, 'john': 49, 'macedonia': 50, 'named': 51, 'off': 52, 'palestine': 53, 'player': 54, 'position': 55, 'recorded': 56, 'robert': 57, 'sentence': 58, 'sir': 59, 'smith': 60, 'solo': 61, 'thomas': 62, 'total': 63, 'up': 64, 'would': 65, '  ': 66, '$': 67, '13th': 68, 'abandoned': 69, 'add': 70, 'also': 71, 'anglicus': 72, 'annular': 73, 'another': 74, 'appearance': 75, 'apu': 76, 'are': 77, 'area': 78, 'army': 79, 'as': 80, 'at': 81, 'attacked': 82, 'attacks': 83, 'azaria': 84, 'batsmen': 85, 'be': 86, 'bear': 87, 'began': 88, 'being': 89, 'binomial': 90, 'bo': 91, 'borgnine': 92, 'bowlers': 93, 'brooke': 94, 'brought': 95, 'camp': 96, 'campers': 97, 'chris': 98, 'circle': 99, 'commented': 100, 'consisting': 101, 'constitution': 102, 'correct': 103, 'cottage': 104, 'county': 105, 'courtney': 106, 'creature': 107, 'cricket': 108, 'crushing': 109, 'dark': 110, 'davis': 111, 'death': 112, 'deprecating': 113, 'devotion': 114, 'diameter': 115, 'doing': 116, 'dominate': 117, 'double': 118, 'due': 119, 'eagle': 120, 'edwin': 121, 'eight': 122, 'episode': 123, 'ernest': 124, 'even': 125, 'fails': 126, 'fight': 127, 'film': 128, 'finally': 129, 'finding': 130, 'flanders': 131, 'flee': 132, 'foot': 133, 'forced': 134, 'form': 135, 'four': 136, 'fourth': 137, 'friday': 138, 'friedrich': 139, 'friend': 140, 'from': 141, 'furthered': 142, 'garden': 143, 'gertrude': 144, 'get': 145, 'government': 146, 'greatly': 147, 'hands': 148, 'hank': 149, 'have': 150, 'hell': 151, 'highest': 152, 'him': 153, 'holl': 154, 'homer': 155, 'hunted': 156, 'idea': 157, 'implied': 158, 'influenced': 159, 'inswing': 160, 'into': 161, 'ironic': 162, 'ironically': 163, 'it': 164, 'jason': 165, 'jekyll': 166, 'johnson': 167, 'junior': 168, 'kg': 169, 'knife': 170, 'late': 171, 'later': 172, 'law': 173, 'lbw': 174, 'led': 175, 'legislation': 176, 'life': 177, 'line': 178, 'linebackers': 179, 'long': 180, 'losses': 181, 'making': 182, 'mckay': 183, 'meanwhile': 184, 'men': 185, 'mountain': 186, 'much': 187, 'name': 188, 'ned': 189, 'neglected': 190, 'neither': 191, 'nelson': 192, 'no': 193, 'not': 194, 'one': 195, 'or': 196, 'other': 197, 'out': 198, 'own': 199, 'parliament': 200, 'pass': 201, 'patterson': 202, 'paul': 203, 'person': 204, 'piece': 205, 'piracy': 206, 'pirates': 207, 'plants': 208, 'played': 209, 'pounds': 210, 'powers': 211, 'practice': 212, 'presidential': 213, 'proper': 214, 'proposal': 215, 'provide': 216, 'provides': 217, 'quarter': 218, 'real': 219, 'recording': 220, 'recovering': 221, 'recovery': 222, 'relationship': 223, 'replied': 224, 'resigned': 225, 'respectively': 226, 'responsible': 227, 'resumed': 228, 'road': 229, 'role': 230, 'route': 231, 'sec': 232, 'second': 233, 'seeing': 234, 'self': 235, 'series': 236, 'serve': 237, 'shot': 238, 'show': 239, 'silver': 240, 'so': 241, 'specific': 242, 'spin': 243, 'sport': 244, 'standardised': 245, 'standing': 246, 'stating': 247, 'stealing': 248, 'studio': 249, 'summer': 250, 'supplied': 251, 'swamp': 252, 'swiss': 253, 'tackles': 254, 'tadman': 255, 'take': 256, 'tangled': 257, 'texas': 258, 'themselves': 259, 'this': 260, 'three': 261, 'toss': 262, 'touchdown': 263, 'traditional': 264, 'transferred': 265, 'trapped': 266, 'tries': 267, 'tudman': 268, 'two': 269, 'unseen': 270, 'voice': 271, 'week': 272, 'weight': 273, 'what': 274, 'when': 275, 'which': 276, 'whose': 277, 'williams': 278, 'work': 279, 'working': 280, 'worse': 281, 'wrong': 282, 'wrote': 283})\n"
     ]
    }
   ],
   "source": [
    "vocab = TEXT.vocab\n",
    "print(vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 0,\n",
       " '<pad>': 1,\n",
       " '<': 2,\n",
       " '>': 3,\n",
       " 'the': 4,\n",
       " 'unk': 5,\n",
       " 'and': 6,\n",
       " 'blank_token': 7,\n",
       " 'to': 8,\n",
       " 'a': 9,\n",
       " 'N': 10,\n",
       " 'was': 11,\n",
       " 'in': 12,\n",
       " 'of': 13,\n",
       " 'for': 14,\n",
       " 'by': 15,\n",
       " 'after': 16,\n",
       " 'his': 17,\n",
       " 'defensive': 18,\n",
       " 'is': 19,\n",
       " 'principal': 20,\n",
       " 'that': 21,\n",
       " 'who': 22,\n",
       " 'with': 23,\n",
       " \"'s\": 24,\n",
       " 'assisted': 25,\n",
       " 'but': 26,\n",
       " 'fumble': 27,\n",
       " 'gold': 28,\n",
       " 'had': 29,\n",
       " 'he': 30,\n",
       " 'james': 31,\n",
       " 'seven': 32,\n",
       " 'they': 33,\n",
       " 'were': 34,\n",
       " 'while': 35,\n",
       " 'an': 36,\n",
       " 'between': 37,\n",
       " 'coach': 38,\n",
       " 'coin': 39,\n",
       " 'dollar': 40,\n",
       " 'egypt': 41,\n",
       " 'end': 42,\n",
       " 'gallipoli': 43,\n",
       " 'great': 44,\n",
       " 'guitar': 45,\n",
       " 'henry': 46,\n",
       " 'i.': 47,\n",
       " 'italy': 48,\n",
       " 'john': 49,\n",
       " 'macedonia': 50,\n",
       " 'named': 51,\n",
       " 'off': 52,\n",
       " 'palestine': 53,\n",
       " 'player': 54,\n",
       " 'position': 55,\n",
       " 'recorded': 56,\n",
       " 'robert': 57,\n",
       " 'sir': 59,\n",
       " 'smith': 60,\n",
       " 'solo': 61,\n",
       " 'thomas': 62,\n",
       " 'total': 63,\n",
       " 'up': 64,\n",
       " 'would': 65,\n",
       " '  ': 66,\n",
       " '$': 67,\n",
       " '13th': 68,\n",
       " 'abandoned': 69,\n",
       " 'add': 70,\n",
       " 'also': 71,\n",
       " 'anglicus': 72,\n",
       " 'annular': 73,\n",
       " 'another': 74,\n",
       " 'appearance': 75,\n",
       " 'apu': 76,\n",
       " 'are': 77,\n",
       " 'area': 78,\n",
       " 'army': 79,\n",
       " 'as': 80,\n",
       " 'at': 81,\n",
       " 'attacked': 82,\n",
       " 'attacks': 83,\n",
       " 'azaria': 84,\n",
       " 'batsmen': 85,\n",
       " 'be': 86,\n",
       " 'bear': 87,\n",
       " 'began': 88,\n",
       " 'being': 89,\n",
       " 'binomial': 90,\n",
       " 'bo': 91,\n",
       " 'borgnine': 92,\n",
       " 'bowlers': 93,\n",
       " 'brooke': 94,\n",
       " 'brought': 95,\n",
       " 'camp': 96,\n",
       " 'campers': 97,\n",
       " 'chris': 98,\n",
       " 'circle': 99,\n",
       " 'commented': 100,\n",
       " 'consisting': 101,\n",
       " 'constitution': 102,\n",
       " 'correct': 103,\n",
       " 'cottage': 104,\n",
       " 'county': 105,\n",
       " 'courtney': 106,\n",
       " 'creature': 107,\n",
       " 'cricket': 108,\n",
       " 'crushing': 109,\n",
       " 'dark': 110,\n",
       " 'davis': 111,\n",
       " 'death': 112,\n",
       " 'deprecating': 113,\n",
       " 'devotion': 114,\n",
       " 'diameter': 115,\n",
       " 'doing': 116,\n",
       " 'dominate': 117,\n",
       " 'double': 118,\n",
       " 'due': 119,\n",
       " 'eagle': 120,\n",
       " 'edwin': 121,\n",
       " 'eight': 122,\n",
       " 'episode': 123,\n",
       " 'ernest': 124,\n",
       " 'even': 125,\n",
       " 'fails': 126,\n",
       " 'fight': 127,\n",
       " 'film': 128,\n",
       " 'finally': 129,\n",
       " 'finding': 130,\n",
       " 'flanders': 131,\n",
       " 'flee': 132,\n",
       " 'foot': 133,\n",
       " 'forced': 134,\n",
       " 'form': 135,\n",
       " 'four': 136,\n",
       " 'fourth': 137,\n",
       " 'friday': 138,\n",
       " 'friedrich': 139,\n",
       " 'friend': 140,\n",
       " 'from': 141,\n",
       " 'furthered': 142,\n",
       " 'garden': 143,\n",
       " 'gertrude': 144,\n",
       " 'get': 145,\n",
       " 'government': 146,\n",
       " 'greatly': 147,\n",
       " 'hands': 148,\n",
       " 'hank': 149,\n",
       " 'have': 150,\n",
       " 'hell': 151,\n",
       " 'highest': 152,\n",
       " 'him': 153,\n",
       " 'holl': 154,\n",
       " 'homer': 155,\n",
       " 'hunted': 156,\n",
       " 'idea': 157,\n",
       " 'implied': 158,\n",
       " 'influenced': 159,\n",
       " 'inswing': 160,\n",
       " 'into': 161,\n",
       " 'ironic': 162,\n",
       " 'ironically': 163,\n",
       " 'it': 164,\n",
       " 'jason': 165,\n",
       " 'jekyll': 166,\n",
       " 'johnson': 167,\n",
       " 'junior': 168,\n",
       " 'kg': 169,\n",
       " 'knife': 170,\n",
       " 'late': 171,\n",
       " 'later': 172,\n",
       " 'law': 173,\n",
       " 'lbw': 174,\n",
       " 'led': 175,\n",
       " 'legislation': 176,\n",
       " 'life': 177,\n",
       " 'line': 178,\n",
       " 'linebackers': 179,\n",
       " 'long': 180,\n",
       " 'losses': 181,\n",
       " 'making': 182,\n",
       " 'mckay': 183,\n",
       " 'meanwhile': 184,\n",
       " 'men': 185,\n",
       " 'mountain': 186,\n",
       " 'much': 187,\n",
       " 'name': 188,\n",
       " 'ned': 189,\n",
       " 'neglected': 190,\n",
       " 'neither': 191,\n",
       " 'nelson': 192,\n",
       " 'no': 193,\n",
       " 'not': 194,\n",
       " 'one': 195,\n",
       " 'or': 196,\n",
       " 'other': 197,\n",
       " 'out': 198,\n",
       " 'own': 199,\n",
       " 'parliament': 200,\n",
       " 'pass': 201,\n",
       " 'patterson': 202,\n",
       " 'paul': 203,\n",
       " 'person': 204,\n",
       " 'piece': 205,\n",
       " 'piracy': 206,\n",
       " 'pirates': 207,\n",
       " 'plants': 208,\n",
       " 'played': 209,\n",
       " 'pounds': 210,\n",
       " 'powers': 211,\n",
       " 'practice': 212,\n",
       " 'presidential': 213,\n",
       " 'proper': 214,\n",
       " 'proposal': 215,\n",
       " 'provide': 216,\n",
       " 'provides': 217,\n",
       " 'quarter': 218,\n",
       " 'real': 219,\n",
       " 'recording': 220,\n",
       " 'recovering': 221,\n",
       " 'recovery': 222,\n",
       " 'relationship': 223,\n",
       " 'replied': 224,\n",
       " 'resigned': 225,\n",
       " 'respectively': 226,\n",
       " 'responsible': 227,\n",
       " 'resumed': 228,\n",
       " 'road': 229,\n",
       " 'role': 230,\n",
       " 'route': 231,\n",
       " 'sec': 232,\n",
       " 'second': 233,\n",
       " 'seeing': 234,\n",
       " 'self': 235,\n",
       " 'series': 236,\n",
       " 'serve': 237,\n",
       " 'shot': 238,\n",
       " 'show': 239,\n",
       " 'silver': 240,\n",
       " 'so': 241,\n",
       " 'specific': 242,\n",
       " 'spin': 243,\n",
       " 'sport': 244,\n",
       " 'standardised': 245,\n",
       " 'standing': 246,\n",
       " 'stating': 247,\n",
       " 'stealing': 248,\n",
       " 'studio': 249,\n",
       " 'summer': 250,\n",
       " 'supplied': 251,\n",
       " 'swamp': 252,\n",
       " 'swiss': 253,\n",
       " 'tackles': 254,\n",
       " 'tadman': 255,\n",
       " 'take': 256,\n",
       " 'tangled': 257,\n",
       " 'texas': 258,\n",
       " 'themselves': 259,\n",
       " 'this': 260,\n",
       " 'three': 261,\n",
       " 'toss': 262,\n",
       " 'touchdown': 263,\n",
       " 'traditional': 264,\n",
       " 'transferred': 265,\n",
       " 'trapped': 266,\n",
       " 'tries': 267,\n",
       " 'tudman': 268,\n",
       " 'two': 269,\n",
       " 'unseen': 270,\n",
       " 'voice': 271,\n",
       " 'week': 272,\n",
       " 'weight': 273,\n",
       " 'what': 274,\n",
       " 'when': 275,\n",
       " 'which': 276,\n",
       " 'whose': 277,\n",
       " 'williams': 278,\n",
       " 'work': 279,\n",
       " 'working': 280,\n",
       " 'worse': 281,\n",
       " 'wrong': 282,\n",
       " 'wrote': 283}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i:vocab.stoi[i] for i in vocab.stoi if i!='sentence'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In torchvision and PyTorch, the processing and batching of\n",
    "# data is handled by DataLoaders. For some reason, torchtext\n",
    "# has renamed the objects that do the exact same thing to\n",
    "# Iterators. The basic functionality is the same\n",
    "\n",
    "train_iter, test_iter = Iterator.splits(\n",
    "        (train, test),\n",
    "    \n",
    "        # (91270, 10153) means 91270 for train and 10153 for test,\n",
    "        # the number of examples in each\n",
    "        # That is, we only want to create one \"batch\" for each\n",
    "        # as we are only doing this process in TorchText to convert\n",
    "        # our data into a PyTorch tensor object to be passed around\n",
    "        # the matching networks program in the same way the\n",
    "        # vision data was passed around in a numpy array\n",
    "        # The matching networks program already takes care\n",
    "        # of batching and we don;t want to distrub things too much\n",
    "    \n",
    "        batch_sizes=(20,5),sort_key=None, device=None, batch_size_fn=None, repeat=False, shuffle=None, sort=None, sort_within_batch=None)\n",
    "\n",
    "# train_iter, test_iter = Iterator(dataset=train, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the batch\n",
    "\n",
    "# batch = next(train_iter.__iter__()); batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_iter.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently, the iterator returns a custom datatype\n",
    "# called torchtext.data.Batch.\n",
    "# weâ€™ll convert the batch to a tuple in the form\n",
    "# (x, y) where x is the label tensor\n",
    "# and y is the sentence\n",
    "\n",
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_var):\n",
    "        \n",
    "        self.dl, self.x_var, self.y_var = dl, x_var, y_var # we pass in the list of attributes for x and y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "            \n",
    "            y = getattr(batch, self.y_var) # we assume only one input in this wrapper\n",
    "\n",
    "            yield (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = BatchWrapper(train_iter, \"label\", \"sentence\")\n",
    "test_dl = BatchWrapper(test_iter, \"label\", \"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1, 1, 4, 4, 1, 4, 1, 4, 4, 1, 5]), tensor([[275,  16, 255, 106, 260, 278, 183,  18,  10,  30,  58],\n",
      "        [  4, 268,  29,   2,  11,  71,   2, 178,   6, 190,   1],\n",
      "        [244,  24,  32,   5,   2,  56,   7,  38,  10,   8,   1],\n",
      "        [228, 112,  61,   3,   7, 122,   3,  91,   2,  70,   1],\n",
      "        [ 12,  12,   2,  11,   3,  61,  17, 111,   5,   9,   1],\n",
      "        [ 10,  10,   7,  51,   8,   2, 176, 225,   3, 242,   1],\n",
      "        [ 85,   4,   3,   4,   9,   7,   8,  17,  34, 188,   1],\n",
      "        [ 34, 102, 261, 232,  99,   3, 216,  55, 179,   8,   1],\n",
      "        [198,  11,  25,  18,  78,   4,  14,   8, 203, 135,   1],\n",
      "        [ 13,   2, 254,  54,  23, 233,   9, 237, 192,   9,   1],\n",
      "        [212,   7,   6,  13,   9, 152, 118,  80,   6, 214,   1],\n",
      "        [  6,   3,  56,   4,  32,  63, 120,   4,   2,  90,   1],\n",
      "        [  4,   6,   9, 272, 133,  14,  67,  18,   5,  26,   1],\n",
      "        [  2, 187,  18,  16, 115,   4,  10,   2,   3, 195,   1],\n",
      "        [  7,  13, 263, 182,  12, 207,  28,   7,   2,  11,   1],\n",
      "        [  3,   4,  16,  32,  10,   6,  39,   3,   5, 251,   1],\n",
      "        [174, 213, 221,  63,   6,   9,   6,  38,   3,  12,   1],\n",
      "        [173, 211,  98,   2,   4, 134, 283,  14,  22,  10,   1],\n",
      "        [209,  34, 167,   7, 273,  27,   8, 258,  29,  15,   1],\n",
      "        [161, 265,  24,   3,  13,   1, 202,   1,  10, 139,   1],\n",
      "        [  4,   8,  27,  23,   4,   1,  22,   1,   6, 154,   1],\n",
      "        [148,   4, 171, 136, 238,   1, 224,   1,  10,  47,   1],\n",
      "        [ 13, 200,  12,  14,  11,   1, 247,   1,   2,   2,   1],\n",
      "        [ 52,   6,   4, 181, 245,   1,  21,   1,   7,   5,   1],\n",
      "        [243,   4, 137,   9,   8,   1,   4,   1,   3,   3,   1],\n",
      "        [  6, 146, 218,  27,  10,   1,  73,   1, 226, 276,   1],\n",
      "        [160,   1,   1, 222, 210,   1,  28,   1,   1,  11,   1],\n",
      "        [ 93,   1,   1,   6,  10,   1,  40,   1,   1, 172,   1],\n",
      "        [ 22,   1,   1, 269,  10,   1,  65,   1,   1,   2,   1],\n",
      "        [ 88,   1,   1, 201, 169,   1, 194,   1,   1,   7,   1],\n",
      "        [  8,   1,   1,   2,   1,   1, 279,   1,   1,   3,   1],\n",
      "        [117,   1,   1,   5,   1,   1,   6,   1,   1,   8,   1],\n",
      "        [105,   1,   1,   3,   1,   1, 191,   1,   1,  47,   1],\n",
      "        [108,   1,   1,   1,   1,   1,  65,   1,   1,  72,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,  74,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1, 215,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,   8,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1, 150,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,  40,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1, 205,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1, 101,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,  13,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,   9,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,  28,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,   2,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,   5,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,   3,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,  12,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,   9,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1, 240,   1,   1,   1,   1],\n",
      "        [  1,   1,   1,   1,   1,   1,  39,   1,   1,   1,   1]]))\n"
     ]
    }
   ],
   "source": [
    "X = next(train_dl.__iter__())\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 4, 4, 1, 4, 1, 4, 4, 1])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_0 = X[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_1 = X[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Y_0.argsort()\n",
    "Y_0p = Y_0[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[275  16 260 183  30 255 106 278  18  10]\n",
      " [  4 268  11   2 190  29   2  71 178   6]\n",
      " [244  24   2   7   8  32   5  56  38  10]\n",
      " [228 112   7   3  70  61   3 122  91   2]\n",
      " [ 12  12   3  17   9   2  11  61 111   5]\n",
      " [ 10  10   8 176 242   7  51   2 225   3]\n",
      " [ 85   4   9   8 188   3   4   7  17  34]\n",
      " [ 34 102  99 216   8 261 232   3  55 179]\n",
      " [198  11  78  14 135  25  18   4   8 203]\n",
      " [ 13   2  23   9   9 254  54 233 237 192]\n",
      " [212   7   9 118 214   6  13 152  80   6]\n",
      " [  6   3  32 120  90  56   4  63   4   2]\n",
      " [  4   6 133  67  26   9 272  14  18   5]\n",
      " [  2 187 115  10 195  18  16   4   2   3]\n",
      " [  7  13  12  28  11 263 182 207   7   2]\n",
      " [  3   4  10  39 251  16  32   6   3   5]\n",
      " [174 213   6   6  12 221  63   9  38   3]\n",
      " [173 211   4 283  10  98   2 134  14  22]\n",
      " [209  34 273   8  15 167   7  27 258  29]\n",
      " [161 265  13 202 139  24   3   1   1  10]\n",
      " [  4   8   4  22 154  27  23   1   1   6]\n",
      " [148   4 238 224  47 171 136   1   1  10]\n",
      " [ 13 200  11 247   2  12  14   1   1   2]\n",
      " [ 52   6 245  21   5   4 181   1   1   7]\n",
      " [243   4   8   4   3 137   9   1   1   3]\n",
      " [  6 146  10  73 276 218  27   1   1 226]\n",
      " [160   1 210  28  11   1 222   1   1   1]\n",
      " [ 93   1  10  40 172   1   6   1   1   1]\n",
      " [ 22   1  10  65   2   1 269   1   1   1]\n",
      " [ 88   1 169 194   7   1 201   1   1   1]\n",
      " [  8   1   1 279   3   1   2   1   1   1]\n",
      " [117   1   1   6   8   1   5   1   1   1]\n",
      " [105   1   1 191  47   1   3   1   1   1]\n",
      " [108   1   1  65  72   1   1   1   1   1]\n",
      " [  1   1   1  74   1   1   1   1   1   1]\n",
      " [  1   1   1 215   1   1   1   1   1   1]\n",
      " [  1   1   1   8   1   1   1   1   1   1]\n",
      " [  1   1   1 150   1   1   1   1   1   1]\n",
      " [  1   1   1  40   1   1   1   1   1   1]\n",
      " [  1   1   1 205   1   1   1   1   1   1]\n",
      " [  1   1   1 101   1   1   1   1   1   1]\n",
      " [  1   1   1  13   1   1   1   1   1   1]\n",
      " [  1   1   1   9   1   1   1   1   1   1]\n",
      " [  1   1   1  28   1   1   1   1   1   1]\n",
      " [  1   1   1   2   1   1   1   1   1   1]\n",
      " [  1   1   1   5   1   1   1   1   1   1]\n",
      " [  1   1   1   3   1   1   1   1   1   1]\n",
      " [  1   1   1  12   1   1   1   1   1   1]\n",
      " [  1   1   1   9   1   1   1   1   1   1]\n",
      " [  1   1   1 240   1   1   1   1   1   1]\n",
      " [  1   1   1  39   1   1   1   1   1   1]]\n"
     ]
    }
   ],
   "source": [
    "Y_1p = Y_1[:,p]\n",
    "print(Y_1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 1, 1, 1, 1, 4, 4, 4, 4, 4], dtype=int64), array([[275,  16, 260, 183,  30, 255, 106, 278,  18,  10],\n",
      "       [  4, 268,  11,   2, 190,  29,   2,  71, 178,   6],\n",
      "       [244,  24,   2,   7,   8,  32,   5,  56,  38,  10],\n",
      "       [228, 112,   7,   3,  70,  61,   3, 122,  91,   2],\n",
      "       [ 12,  12,   3,  17,   9,   2,  11,  61, 111,   5],\n",
      "       [ 10,  10,   8, 176, 242,   7,  51,   2, 225,   3],\n",
      "       [ 85,   4,   9,   8, 188,   3,   4,   7,  17,  34],\n",
      "       [ 34, 102,  99, 216,   8, 261, 232,   3,  55, 179],\n",
      "       [198,  11,  78,  14, 135,  25,  18,   4,   8, 203],\n",
      "       [ 13,   2,  23,   9,   9, 254,  54, 233, 237, 192],\n",
      "       [212,   7,   9, 118, 214,   6,  13, 152,  80,   6],\n",
      "       [  6,   3,  32, 120,  90,  56,   4,  63,   4,   2],\n",
      "       [  4,   6, 133,  67,  26,   9, 272,  14,  18,   5],\n",
      "       [  2, 187, 115,  10, 195,  18,  16,   4,   2,   3],\n",
      "       [  7,  13,  12,  28,  11, 263, 182, 207,   7,   2],\n",
      "       [  3,   4,  10,  39, 251,  16,  32,   6,   3,   5],\n",
      "       [174, 213,   6,   6,  12, 221,  63,   9,  38,   3],\n",
      "       [173, 211,   4, 283,  10,  98,   2, 134,  14,  22],\n",
      "       [209,  34, 273,   8,  15, 167,   7,  27, 258,  29],\n",
      "       [161, 265,  13, 202, 139,  24,   3,   1,   1,  10],\n",
      "       [  4,   8,   4,  22, 154,  27,  23,   1,   1,   6],\n",
      "       [148,   4, 238, 224,  47, 171, 136,   1,   1,  10],\n",
      "       [ 13, 200,  11, 247,   2,  12,  14,   1,   1,   2],\n",
      "       [ 52,   6, 245,  21,   5,   4, 181,   1,   1,   7],\n",
      "       [243,   4,   8,   4,   3, 137,   9,   1,   1,   3],\n",
      "       [  6, 146,  10,  73, 276, 218,  27,   1,   1, 226],\n",
      "       [160,   1, 210,  28,  11,   1, 222,   1,   1,   1],\n",
      "       [ 93,   1,  10,  40, 172,   1,   6,   1,   1,   1],\n",
      "       [ 22,   1,  10,  65,   2,   1, 269,   1,   1,   1],\n",
      "       [ 88,   1, 169, 194,   7,   1, 201,   1,   1,   1],\n",
      "       [  8,   1,   1, 279,   3,   1,   2,   1,   1,   1],\n",
      "       [117,   1,   1,   6,   8,   1,   5,   1,   1,   1],\n",
      "       [105,   1,   1, 191,  47,   1,   3,   1,   1,   1],\n",
      "       [108,   1,   1,  65,  72,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,  74,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1, 215,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,   8,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1, 150,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,  40,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1, 205,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1, 101,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,  13,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,   9,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,  28,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,   2,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,   5,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,   3,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,  12,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,   9,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1, 240,   1,   1,   1,   1,   1,   1],\n",
      "       [  1,   1,   1,  39,   1,   1,   1,   1,   1,   1]], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "Yp = (Y_0p, Y_1p)\n",
    "print(Yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 1, 4, 4, 1, 4, 1, 4, 4, 1], dtype=int64), array([[275,  16, 255, 106, 260, 278, 183,  18,  10,  30],\n",
      "       [  4, 268,  29,   2,  11,  71,   2, 178,   6, 190],\n",
      "       [244,  24,  32,   5,   2,  56,   7,  38,  10,   8],\n",
      "       [228, 112,  61,   3,   7, 122,   3,  91,   2,  70],\n",
      "       [ 12,  12,   2,  11,   3,  61,  17, 111,   5,   9],\n",
      "       [ 10,  10,   7,  51,   8,   2, 176, 225,   3, 242],\n",
      "       [ 85,   4,   3,   4,   9,   7,   8,  17,  34, 188],\n",
      "       [ 34, 102, 261, 232,  99,   3, 216,  55, 179,   8],\n",
      "       [198,  11,  25,  18,  78,   4,  14,   8, 203, 135],\n",
      "       [ 13,   2, 254,  54,  23, 233,   9, 237, 192,   9],\n",
      "       [212,   7,   6,  13,   9, 152, 118,  80,   6, 214],\n",
      "       [  6,   3,  56,   4,  32,  63, 120,   4,   2,  90],\n",
      "       [  4,   6,   9, 272, 133,  14,  67,  18,   5,  26],\n",
      "       [  2, 187,  18,  16, 115,   4,  10,   2,   3, 195],\n",
      "       [  7,  13, 263, 182,  12, 207,  28,   7,   2,  11],\n",
      "       [  3,   4,  16,  32,  10,   6,  39,   3,   5, 251],\n",
      "       [174, 213, 221,  63,   6,   9,   6,  38,   3,  12],\n",
      "       [173, 211,  98,   2,   4, 134, 283,  14,  22,  10],\n",
      "       [209,  34, 167,   7, 273,  27,   8, 258,  29,  15],\n",
      "       [161, 265,  24,   3,  13,   1, 202,   1,  10, 139],\n",
      "       [  4,   8,  27,  23,   4,   1,  22,   1,   6, 154],\n",
      "       [148,   4, 171, 136, 238,   1, 224,   1,  10,  47],\n",
      "       [ 13, 200,  12,  14,  11,   1, 247,   1,   2,   2],\n",
      "       [ 52,   6,   4, 181, 245,   1,  21,   1,   7,   5],\n",
      "       [243,   4, 137,   9,   8,   1,   4,   1,   3,   3],\n",
      "       [  6, 146, 218,  27,  10,   1,  73,   1, 226, 276],\n",
      "       [160,   1,   1, 222, 210,   1,  28,   1,   1,  11],\n",
      "       [ 93,   1,   1,   6,  10,   1,  40,   1,   1, 172],\n",
      "       [ 22,   1,   1, 269,  10,   1,  65,   1,   1,   2],\n",
      "       [ 88,   1,   1, 201, 169,   1, 194,   1,   1,   7],\n",
      "       [  8,   1,   1,   2,   1,   1, 279,   1,   1,   3],\n",
      "       [117,   1,   1,   5,   1,   1,   6,   1,   1,   8],\n",
      "       [105,   1,   1,   3,   1,   1, 191,   1,   1,  47],\n",
      "       [108,   1,   1,   1,   1,   1,  65,   1,   1,  72],\n",
      "       [  1,   1,   1,   1,   1,   1,  74,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1, 215,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,   8,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1, 150,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,  40,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1, 205,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1, 101,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,  13,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,   9,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,  28,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,   2,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,   5,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,   3,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,  12,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,   9,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1, 240,   1,   1,   1],\n",
      "       [  1,   1,   1,   1,   1,   1,  39,   1,   1,   1]], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "Y = (Y_0, Y_1)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(next(train_dl.__iter__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(next(train_dl.__iter__())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 2, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dl.__iter__())[0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(next(train_dl.__iter__())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 49,  98,  52, 101,  11,  22,   4,   8,  10, 111,  44],\n",
      "        [ 58,   1,   2,  16,  39,   4,  30,  71,   6,  21,   8],\n",
      "        [  4,   1,   7,  12,   4,  30,  68,  23,  10,  31,  27],\n",
      "        [ 93,   1,   3,  18,  55,  27,  50,  46,   2,  24,  22],\n",
      "        [ 96,   1, 108,   2,  54,  38,  61,  53,   7,  18,  75],\n",
      "        [ 13,   1,  78,   5,  89,  81,   8,  94,   3,   2,  16],\n",
      "        [ 10,   1,   4,   3,  56,   2,  43,  66, 110,   5,  29],\n",
      "        [  2,   1,  97,  19,  79,   5,   2,  87,  72,   3,  17],\n",
      "        [  5,   1,   8,  42,  11,   3,   7, 104,  85,   4,  13],\n",
      "        [  3,   1,  17,  33,   2,   4,   3,  99,  80,  32,  24],\n",
      "        [ 48,   1,  28,   6,   5,  32,  76,  41,   6,  64,   2],\n",
      "        [107,   1,   4,  31,   3,  77,  36,   4,   2,  34,   5],\n",
      "        [ 25,   1, 109,  14,   9,  28,  21,   8,   7,   9,   3],\n",
      "        [ 84,   1,  20,   8,  26,  40,  47,   2,   3,   4,   6],\n",
      "        [  6,   1,  74, 105,   1,  17,  19,   5,   2,  86,  35],\n",
      "        [ 90,   1,  12,  20,   1,  11,  18,   3,   7,   6,  13],\n",
      "        [ 19,   1,  34,  91,   1,   4,   2,  23,   3,  14,  12],\n",
      "        [ 62,   1,   2,  51,   1,  63,   5,   9,  36,  59,   1],\n",
      "        [  1,   1,   5,  69,   1,  67,   3, 103,  16,  15,   1],\n",
      "        [  1,   1,   3,  37,   1,  12, 106,   1,  10,   1,   1],\n",
      "        [  1,   1,  13,  15,   1,   2,  65,   1,   6,   1,   1],\n",
      "        [  1,   1,  25,  70,   1,   7,   9,   1,  10,   1,   1],\n",
      "        [  1,   1,   9,  11,   1,   3,  57,   1,   2,   1,   1],\n",
      "        [  1,   1,  73,   4,   1,  33,  45,   1,   5,   1,   1],\n",
      "        [  1,   1,  14,  60,   1,   6,  82,   1,   3,   1,   1],\n",
      "        [  1,   1,  15,  88,   1,  29,   4,   1,  95,   1,   1],\n",
      "        [  1,   1,  92,   1,   1, 100, 102,   1,   1,   1,   1],\n",
      "        [  1,   1,   6,   1,   1,   9,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,  35,   1,   1,  26,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,  83,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,   2,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,   7,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  1,   1,   3,   1,   1,   1,   1,   1,   1,   1,   1]])\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dl.__iter__())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 11])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "t() expects a 2D tensor, but self is 1D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-543000525590>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mY_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: t() expects a 2D tensor, but self is 1D"
     ]
    }
   ],
   "source": [
    "# Transpose\n",
    "\n",
    "Y_train = next(train_dl.__iter__())[0]\n",
    "X_train = next(train_dl.__iter__())[1]\n",
    "Y_test = next(test_dl.__iter__())[0]\n",
    "X_test = next(test_dl.__iter__())[1]\n",
    "\n",
    "\n",
    "X_train = X_train.t()\n",
    "Y_train = Y_train.t()\n",
    "X_test = X_test.t()\n",
    "Y_test = Y_test.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "\n",
    "# We convert the tensors to numpy arrays\n",
    "# for the Matching Networks code so we  don't\n",
    "# have to change everything that was for numpy arrays\n",
    "# to PyTorch tensors. We could could then convert\n",
    "# back to Tensors when we need them\n",
    "\n",
    "# Cell incomplete, issue with size of train. Should be 90,000, not 9,000 long\n",
    "\n",
    "X_train = X_train.reshape()\n",
    "Y_train = Y_train.reshape()\n",
    "X_test = X_test.reshape()\n",
    "Y_test = Y_test.reshape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to numpy array\n",
    "\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('Y_train.npy', Y_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('Y_test.npy', Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3],\n",
       "        [1, 4],\n",
       "        [2, 5]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
