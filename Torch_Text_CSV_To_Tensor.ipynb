{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The aim of this code is to convert the CSV file of\n",
    "# labels = missing words, and sentences with missing words\n",
    "# into a tensor of numbersthat can be passed through\n",
    "# the matching networks code just like the numpy array\n",
    "# used for the images in the original code based on the\n",
    "# Onmiglot dataset\n",
    "\n",
    "# The numbers in the tensor will be the numbers each word\n",
    "# refers to in the vocabulary we are building\n",
    "# We will not embed at this stage because this is\n",
    "# is done inside the matching network. We are, in effect,\n",
    "# not completing the TorchText proprocessing\n",
    "\n",
    "# This code is a mainly a mixture of two tutorials:\n",
    "# http://anie.me/On-Torchtext/\n",
    "# https://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "\n",
    "# Comments are a mixture of those from the tutorials (most of them)\n",
    "# and my own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext.data import Iterator\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>hank azaria who provides the voice of apu comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>the unseen person or creature that attacks &lt;bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>meanwhile the other junior campers led by er...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>&lt;blank_token&gt; was a guitar player in real life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>seeing ned flanders get it wrong is great but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>rick porter of &lt; unk &gt; N it wrote in that he w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>meanwhile the other junior campers led by er...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>ernest &lt;blank_token&gt; guest starred in the epis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>&lt;blank_token&gt; apologized because he felt that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>borgnine</td>\n",
       "      <td>in her book my life as a N year old boy cart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tackles</td>\n",
       "      <td>tadman had seven solo &lt;blank_token&gt; three assi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tackles</td>\n",
       "      <td>defensive line coach bo davis resigned his pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tackles</td>\n",
       "      <td>N and N &lt; unk &gt; were linebackers paul nelson a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tackles</td>\n",
       "      <td>courtney &lt; unk &gt; was named the sec defensive p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tackles</td>\n",
       "      <td>williams also recorded eight solo &lt;blank_token...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tackles</td>\n",
       "      <td>behind defensive mvp burt miami had one player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tackles</td>\n",
       "      <td>in addition the ecu defense ranked eleventh na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tackles</td>\n",
       "      <td>burt the other mvp accumulated nine &lt;blank_tok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tackles</td>\n",
       "      <td>the other interception came from defensive bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tackles</td>\n",
       "      <td>brown finished the regular season with N &lt;blan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           sentence\n",
       "0   borgnine  hank azaria who provides the voice of apu comm...\n",
       "1   borgnine  the unseen person or creature that attacks <bl...\n",
       "2   borgnine    meanwhile the other junior campers led by er...\n",
       "3   borgnine  <blank_token> was a guitar player in real life...\n",
       "4   borgnine  seeing ned flanders get it wrong is great but ...\n",
       "5   borgnine  rick porter of < unk > N it wrote in that he w...\n",
       "6   borgnine    meanwhile the other junior campers led by er...\n",
       "7   borgnine  ernest <blank_token> guest starred in the epis...\n",
       "8   borgnine  <blank_token> apologized because he felt that ...\n",
       "9   borgnine    in her book my life as a N year old boy cart...\n",
       "10   tackles  tadman had seven solo <blank_token> three assi...\n",
       "11   tackles  defensive line coach bo davis resigned his pos...\n",
       "12   tackles  N and N < unk > were linebackers paul nelson a...\n",
       "13   tackles  courtney < unk > was named the sec defensive p...\n",
       "14   tackles  williams also recorded eight solo <blank_token...\n",
       "15   tackles  behind defensive mvp burt miami had one player...\n",
       "16   tackles  in addition the ecu defense ranked eleventh na...\n",
       "17   tackles  burt the other mvp accumulated nine <blank_tok...\n",
       "18   tackles  the other interception came from defensive bac...\n",
       "19   tackles  brown finished the regular season with N <blan..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what the data looks like\n",
    "\n",
    "pd.read_csv(\"Adrian_data/train.csv\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spacy to define a function to \n",
    "# tokenize, or split up, into individual words\n",
    "# the labels and sentences Note the labels are already\n",
    "# individual words\n",
    "\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "# We first define a Field, this is a class that contains\n",
    "# information on how you want the data preprocessed. It acts\n",
    "# like an instruction manual that data.TabularDataset will use.\n",
    "# We define two fields, one for the sentencesm and one for the\n",
    "# labels\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenizer)\n",
    "LABEL = data.Field(sequential=False, is_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fields know what to do when given raw data.\n",
    "# Now, we need to tell the fields what data it\n",
    "# should work on. This is where we use Datasets.\n",
    "\n",
    "# The splits method creates a dataset for the train\n",
    "# and test data by applying the same processing.\n",
    "\n",
    "train, test = data.TabularDataset.splits(\n",
    "        path='Adrian_data/', train='train.csv', test='test.csv', format='csv',\n",
    "        fields=[('label', LABEL), ('sentence', TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.data.dataset.TabularDataset"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torchtext handles mapping words to integers, but\n",
    "# it has to be told the full range of words it should\n",
    "# handle. In our case, we probably want to build the\n",
    "# vocabulary on the training set only, so we run the\n",
    "# following code\n",
    "\n",
    "TEXT.build_vocab(train)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "# This makes torchtext go through all the elements in the\n",
    "# training set, check the contents corresponding to the TEXT\n",
    "# field, and register the words in its vocabulary. Torchtext\n",
    "# has its own class called Vocab for handling the vocabulary.\n",
    "# The Vocab class holds a mapping from word to id in its stoi\n",
    "# attribute and a reverse mapping in its itos attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.vocab.Vocab object at 0x00000233EBF5A668>\n"
     ]
    }
   ],
   "source": [
    "vocab = TEXT.vocab\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In torchvision and PyTorch, the processing and batching of\n",
    "# data is handled by DataLoaders. For some reason, torchtext\n",
    "# has renamed the objects that do the exact same thing to\n",
    "# Iterators. The basic functionality is the same\n",
    "\n",
    "train_iter, test_iter = Iterator.splits(\n",
    "        (train, test), sort_key=lambda x: len(x.Text),\n",
    "    \n",
    "        # (9000, 1000) means 9000 for train and 1000 for test\n",
    "        # That is, we only want to create one \"batch\" for each\n",
    "        # as we are only doing this process in TorchText to convert\n",
    "        # our data into a PyTorch tensor object to be passed around\n",
    "        # the matching networks program in the same way the\n",
    "        # vision data was passed around in a numpy array\n",
    "        # The matching networks program already takes care\n",
    "        # of batching and we don;t want to distrub things too much\n",
    "    \n",
    "        batch_sizes=(9000, 1000)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 9000]\n",
      "\t[.label]:[torch.LongTensor of size 9000]\n",
      "\t[.sentence]:[torch.LongTensor of size 159x9000]\n"
     ]
    }
   ],
   "source": [
    "# Look at the batch\n",
    "\n",
    "# batch = next(train_iter.__iter__()); batch\n",
    "\n",
    "batch = next(iter(train_iter))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.data.batch.Batch"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently, the iterator returns a custom datatype\n",
    "# called torchtext.data.Batch.\n",
    "# weâ€™ll convert the batch to a tuple in the form\n",
    "# (x, y) where x is the label tensor\n",
    "# and y is the sentence\n",
    "\n",
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_var):\n",
    "        self.dl, self.x_var, self.y_var = dl, x_var, y_var # we pass in the list of attributes for x and y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "            \n",
    "            y = getattr(batch, self.y_var) # we assume only one input in this wrapper\n",
    "\n",
    "            yield (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = BatchWrapper(train_iter, \"label\", \"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2368, 2819, 6461,  ...,  286, 3566, 8939]),\n",
       " tensor([[  17,    3,    2,  ...,   17,   95, 1881],\n",
       "         [ 679,    7,  211,  ...,    2, 1978,   11],\n",
       "         [3238,    4,    6,  ...,   43,  306,  847],\n",
       "         ...,\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(next(train_dl.__iter__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(next(train_dl.__iter__())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(next(train_dl.__iter__())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9000])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([219, 9000])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could not convert these to numpy arrays\n",
    "# for the Matching Networks code so we  don't\n",
    "# have to change everything that was for numpy arrays\n",
    "# to PyTorch tensors. We could could then convert\n",
    "# back to Tensors when we need them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
